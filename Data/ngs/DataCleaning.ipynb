{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca5119c",
   "metadata": {},
   "source": [
    "NGS data cleaning template  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d427d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "## pip install chardet - to detect file encoding\n",
    "# Detecting the encoding of a CSV file using chardet\n",
    "import chardet\n",
    "\n",
    "with open('ngs.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read(100000))\n",
    "    print(result)  # Output: {'encoding': 'Windows-1252', 'confidence': 0.99, 'language': ''}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a243e408",
   "metadata": {},
   "source": [
    "Step 1: Find the cut-off point and remove unnecessary information at the end of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50fea8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective Date: 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "# iporting the dataset and extract effective date\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv('ngs.csv',encoding='cp1252',header = None)  # Use the detected encoding\n",
    "\n",
    "# Extract effective date from the first cell\n",
    "first_cell = df_raw.iloc[0, 0]\n",
    "import re\n",
    "match = re.search(r'\\d{4}-\\d{2}-\\d{2}', str(first_cell))\n",
    "effective_date = match.group(0) if match else None\n",
    "\n",
    "print(f\"Effective Date: {effective_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "556a141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut main table before row: 1947\n"
     ]
    }
   ],
   "source": [
    "# Skip the first row which contains the effective date\n",
    "df = pd.read_csv('ngs.csv', encoding='cp1252',skiprows=1)  \n",
    "\n",
    "# find the cut-off point \n",
    "first_col = df.columns[0] \n",
    "cutoff_index = df[\n",
    "    df[first_col].astype(str).str.contains(\n",
    "        r\"The value \\(AUD\\) and weighting \\(%\\) sub totals may not sum to 100%\", na=False\n",
    "    )\n",
    "].index.min()\n",
    "print(\"Cut main table before row:\", cutoff_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8c55249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the main table and summary table\n",
    "df_main = df.loc[:cutoff_index - 2]   # all rows before cutoff\n",
    "df_summary = df.loc[cutoff_index:]    # cutoff row and everything after\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0865d",
   "metadata": {},
   "source": [
    "Step 2: Add 'Effective Date' and 'Fund Name' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add 'Effective Date' and 'Fund Name' columns\n",
    "df_main['Effective Date'] = effective_date\n",
    "df_main['Fund Name'] = 'NGS'\n",
    "df_main['Option Name'] = 'Balanced Growth'\n",
    "print(df_main.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04a19f4",
   "metadata": {},
   "source": [
    "Step 3: Handle Subtotal/ Merge and Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "006ce7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle 'Sub Total' rows\n",
    "import numpy as np\n",
    "\n",
    "def transform_asset_class_column(df):\n",
    "    \"\"\"\n",
    "    RULES:\n",
    "    1. \"TOTAL INVESMENT ITEMS\" → NAME OF INSTITUTION\n",
    "    2. \"SUB TOTAL...\" strings → split across multiple columns\n",
    "    3. Other values remain unchanged\n",
    "    \"\"\"\n",
    "    df_transformed = df.copy()\n",
    "    \n",
    "    for idx, value in enumerate(df_transformed['ASSET CLASS']):\n",
    "        if pd.isna(value):\n",
    "            continue\n",
    "            \n",
    "        value_str = str(value).strip()\n",
    "        \n",
    "        # Rule 1: Move \"TOTAL INVESTMENT ITEMS\"\n",
    "        if value_str == \"TOTAL INVESTMENT ITEMS\":\n",
    "            df_transformed.loc[idx, 'NAME OF INSTITUTION'] = value_str\n",
    "            df_transformed.loc[idx, 'ASSET CLASS'] = np.nan\n",
    "            \n",
    "        # Rule 2: Handle \"SUB TOTAL\" entries  \n",
    "        elif value_str.startswith(\"SUB TOTAL\"):\n",
    "            parts = value_str.split()\n",
    "            management_type = None\n",
    "            remaining_parts = []\n",
    "            \n",
    "            for i, part in enumerate(parts):\n",
    "                if part in [\"INTERNALLY\", \"EXTERNALLY\"]:\n",
    "                    management_type = part\n",
    "                elif not (part == \"SUB\" or (part == \"TOTAL\" and i > 0 and parts[i-1] == \"SUB\")):\n",
    "                    remaining_parts.append(part)\n",
    "            \n",
    "            df_transformed.loc[idx, 'NAME OF INSTITUTION'] = \"SUB TOTAL\"\n",
    "            if management_type:\n",
    "                df_transformed.loc[idx, 'INTERNALLY MANAGED OR EXTERNALLY MANAGED'] = management_type\n",
    "            if remaining_parts:\n",
    "                df_transformed.loc[idx, 'ASSET CLASS'] = \" \".join(remaining_parts)\n",
    "            else:\n",
    "                df_transformed.loc[idx, 'ASSET CLASS'] = np.nan\n",
    "    \n",
    "    return df_transformed\n",
    "df_main = transform_asset_class_column(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3705ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some columns\n",
    "df_main.rename(columns={\n",
    "    'ASSET CLASS': 'Asset Class Name',\n",
    "    'INTERNALLY MANAGED OR EXTERNALLY MANAGED': 'Int/Ext',\n",
    "    'UNITS HELD': 'Units Held',\n",
    "    'ADDRESS': 'Adress',\n",
    "    'VALUE(AUD)': 'Value (AUD)',\n",
    "    'WEIGHTING(%)': 'Weighting (%)',\n",
    "    '% OWNERSHIP / PROPERTY HELD': '% Ownership'\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert 'Int/Ext' to binary\n",
    "def convert_int_ext(value):\n",
    "    if isinstance(value, str):\n",
    "        val = value.strip().upper()\n",
    "        if val == 'INTERNALLY':\n",
    "            return 0\n",
    "    return 1  # return 1 for 'EXTERNALLY' or any other value\n",
    "\n",
    "df_main['Int/Ext'] = df_main['Int/Ext'].apply(convert_int_ext)\n",
    "\n",
    "# Combine 4 overlapping columns into one\n",
    "df_main['Name/Kind of Investment Item'] = df_main[\n",
    "    ['NAME OF INSTITUTION', \n",
    "     'NAME OF ISSUER / COUNTERPARTY', \n",
    "     'NAME OF FUND MANAGER', \n",
    "     'NAME / KIND OF INVESTMENT ITEM']\n",
    "].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "# Keep Currency column as it is\n",
    "\n",
    "# Split 'SECURITY IDENTIFIER' into 2 columns by space delimeter\n",
    "df_main[['Stock ID', 'Listed Country']] = df_main['SECURITY IDENTIFIER'].str.extract(r'^([^ ]+)\\s+(.*)$')\n",
    "\n",
    "\n",
    "# Final selection and reordering of columns\n",
    "df_main = df_main[[\n",
    "    'Effective Date',\n",
    "    'Fund Name',\n",
    "    'Option Name',\n",
    "    'Asset Class Name',\n",
    "    'Int/Ext',\n",
    "    'Name/Kind of Investment Item',\n",
    "    'CURRENCY',\n",
    "    'Stock ID',\n",
    "    'Listed Country',\n",
    "    '% Ownership',\n",
    "    'Units Held',\n",
    "    'Adress',\n",
    "    'Value (AUD)',\n",
    "    'Weighting (%)'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907df536",
   "metadata": {},
   "source": [
    "Step 4: Standardise column dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change dtype of 'Value(AUD) and 'WEIGHTING(%)' to float\n",
    "\n",
    "# Value(AUD) — remove '$' and ',' and convert to float\n",
    "df_main['Value (AUD)'] = (\n",
    "    df_main['Value (AUD)']\n",
    "    .astype(str)\n",
    "    .str.replace(r'[\\$,]', '', regex=True)\n",
    "    .replace('', pd.NA)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Weighting(%) — remove '%' and convert to float\n",
    "df_main['Weighting (%)'] = (\n",
    "    df_main['Weighting (%)']\n",
    "    .astype(str)\n",
    "    .str.replace('%', '', regex=False)\n",
    "    .replace('', pd.NA)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "print(df_main[['Value (AUD)','Weighting (%)']].info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f90e6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.to_csv('ngs_cleaned.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
